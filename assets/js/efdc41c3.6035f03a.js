"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[876],{8356:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>a,toc:()=>h});var i=t(7624),o=t(4552);const r={},s="Prompt engineering techniques",a={id:"Prompt-engineering-techniques/part-1/Prompt-engineering-techniques",title:"Prompt engineering techniques",description:"OpenAI models like GPT-3 do not learn or adapt during user interactions. They generate responses based on pre-training with a large dataset and do not update their knowledge from individual conversations. Any improvements or updates to the model's capabilities are made through a controlled retraining process by OpenAI, not through real-time learning.",source:"@site/docs/00-Prompt-engineering-techniques/part-1/2-Prompt-engineering-techniques.md",sourceDirName:"00-Prompt-engineering-techniques/part-1",slug:"/Prompt-engineering-techniques/part-1/Prompt-engineering-techniques",permalink:"/Workshop-Interact-with-OpenAI-models/Prompt-engineering-techniques/part-1/Prompt-engineering-techniques",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:2,frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Basic Prompting",permalink:"/Workshop-Interact-with-OpenAI-models/Prompt-engineering-techniques/part-1/Basic-Prompting"},next:{title:"System Message",permalink:"/Workshop-Interact-with-OpenAI-models/Prompt-engineering-techniques/part-2/System-Message"}},l={},h=[{value:"Zero-shot learning",id:"zero-shot-learning",level:2},{value:"Few-shot learning",id:"few-shot-learning",level:2},{value:"Chain of thought prompting",id:"chain-of-thought-prompting",level:2}];function p(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",p:"p",pre:"pre",...(0,o.M)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h1,{id:"prompt-engineering-techniques",children:"Prompt engineering techniques"}),"\n",(0,i.jsx)(n.admonition,{title:"Do OpenAI models learn?",type:"tip",children:(0,i.jsx)(n.p,{children:"OpenAI models like GPT-3 do not learn or adapt during user interactions. They generate responses based on pre-training with a large dataset and do not update their knowledge from individual conversations. Any improvements or updates to the model's capabilities are made through a controlled retraining process by OpenAI, not through real-time learning."})}),"\n",(0,i.jsx)(n.p,{children:"This section discusses prompt engineering techniques that can help LLMs solve certain problems more effectively."}),"\n",(0,i.jsx)(n.h2,{id:"zero-shot-learning",children:"Zero-shot learning"}),"\n",(0,i.jsx)(n.p,{children:"LLMs are trained on such large amounts of data they may be be able to perform some tasks with very little prompting. Try the example below and change the sentence to see what outcomes you find."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",metastring:'title="Enter in the user prompt:"',children:"Classify the text into neutral, negative or positive.\nText: The Contoso Bike Store is a great place to buy a new bike.\nSentiment:\n"})}),"\n",(0,i.jsx)(n.h2,{id:"few-shot-learning",children:"Few-shot learning"}),"\n",(0,i.jsx)(n.p,{children:"If zero-shot learning is failing for your examples and more complex tasks, few shot prompting can provide examples that can better steer the model to the desired outcomes. Examples show the model cleanly how we want it to operate. Try the example below to see the outcome. Can you think of other examples that could leverage few-shot learning?"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",metastring:'title="Enter in the user prompt:"',children:'Headline: "Contoso Bike Store opens new location in Seattle"\nSentiment: Positive\nHeadline: "Contoso Bike Store announces new product line"\nSentiment: Neutral\nHeadline: "Contoso Bike Store recalls faulty bikes"\nSentiment: Negative\nHeadline: "Contoso Bike Store wins award for best customer service"\nSentiment:\n'})}),"\n",(0,i.jsxs)(n.p,{children:["The next two sections are very well described in the ",(0,i.jsx)(n.a,{href:"https://www.linkedin.com/pulse/meet-mr-prompty-break-tasks-down-chain-thought-dynamic-mario-fontana/?trackingId=%2FzJrYZ06TxWwVVLkU7rxug%3D%3D",children:"'Meet Mr Prompty'"})," articles on LinkedIn, thank you author, Mario Fontana, for sharing your insights."]}),"\n",(0,i.jsx)(n.h2,{id:"chain-of-thought-prompting",children:"Chain of thought prompting"}),"\n",(0,i.jsx)(n.p,{children:"In this technique, the LLM is responsible for breaking the task down into smaller steps. The LLM uses its knowledge of the world and its ability to reason. The LLM then generates a chain of thoughts that leads to the solution of the task."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",metastring:'title="Enter in the user prompt:"',children:"I like to ride my bike around the city, but I'm not sure if I should buy a new one or repair my old one. Can you help me decide?\nTake a step-by-step approach in your response, cite sources, and give reasoning before sharing a final answer in the below format: ANSWER is: <name>\n"})}),"\n",(0,i.jsx)(n.admonition,{title:"Assignment",type:"info",children:(0,i.jsx)(n.p,{children:"Create a prompt for the assistant that helps determine the best way of traveling between Amsterdam and London and explain why."})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{})})]})}function d(e={}){const{wrapper:n}={...(0,o.M)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(p,{...e})}):p(e)}},4552:(e,n,t)=>{t.d(n,{I:()=>a,M:()=>s});var i=t(1504);const o={},r=i.createContext(o);function s(e){const n=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:s(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);